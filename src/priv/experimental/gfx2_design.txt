OVERVIEW
========
The basic idea comes from the famous thread "material/shader system" on gamedev 
forum:
  - graphics system is kernel/effect based.
  - graphics system does NOT handle multi-thread problem. It is leaved to higher
    level system.
  - device/graphics data are stored in "surface" class, which can be read/write by both 
    host and graphics system.
  - graphics system has a independent reflection system, that can be used to 
    query informance and usage of kernels, which is thread safe.

RESOLVED ISSUES
===============
- Is it possible to create multiple instances of same kernel?
  - No.
    Why we need that?

- Which on is better, independent constants or constant buffer?
  - Independent constants. It is more intuitive.

- Is it possible to extend an exising kernel library without knowing its 
  internal implementation details?
  - No.
    If a kernel library is mean to be extensible, it should provide its own
    interfaces and rules for kernel and surface implementation.
- use uniform kernel interface or not?
  - pros
    - easy to wrap with multi-thread layer
    - easy for script binding
    - easy for parameter sharing/aliasing
  - cons
    - not intuitive
    - restrict kernel functionalities to that interface.
    - slower then kernel-specific interface.

OPEN ISSUES
===========

- Is it possible to implement kernel with CUDA?
  - It is possible. But it'll be hard to make CUDA kernels compatible with 
    non-CUDA kernels (to let them work together)
- How to create MSAA enabled surface?


RESOLVED USER SCENARIOS
=======================

- draw subset of a mesh: use kernel parameter to set subset properties

- create MSAA surface, render to it, then use it as texture.
  - create surface with hint: "msaa=true"
  - inside surface class, it'll hold a MSAA render target and a non-MSAA 
    texture, and copy/downsample data from RT to texture as needed.

- one shader output a 2D texture that is used as input of another shader that 
  requires 3D texture.

- one shader output a 2D texture that is used by many-many of other shaders.

- 2 draws use same shader. the 1st draw render to texture; the second draw 
  to back buffer.

- render to one face of a cubemap, or one slice of a 3D texture, or one mipmap 
  level of a 2D texture

- adjust kernel behavior from outside
  - use kernel parameter.

- separate depth and stencil buffer.
  - why?

- Adjust global quality parameter (like texture filtering), to increase overall
  rendering quality.
  - bad design. effects should control quality by themselves.

- multi-pass rendering:
	 for( each pass of a kernel )
	 {
	  	draw_mesh_1();
	  	draw_mesh_2();
	  	...
	 }

	 can be refactored to this:

	 for( each kernel in a kernel group ) // treat each pass as a kernel
	 {
	  	draw_mesh_1();
	  	draw_mesh_2();
	  	...
	 }

- dynamic resource: use hints

OPENED USER SCENARIOS
=====================

- user creates too many render targets that can't fit into hardware's local
  memory (like EDRAM)
  - may be resolved by lazy creation
  - check CPU "register renaming" and "buffer renaming" in graphics driver for
    more ideas.
  - by now, we leave that to application: application should always check
    return value of surface creation method.

- kernel convert general CPU data buffer to whatever format it needs:
  - create specific vertice buffer from fat vertex buffer
  - create DXT texture from bitmap image
  - create cubemap from 6 2D textures
  - create mipmpas from single image
  - create normal map from height map
