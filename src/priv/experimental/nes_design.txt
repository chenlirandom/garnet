OVERVIEW
========
The basic idea comes from the famous thread "material/shader system" on gamedev 
forum:
  - Each effect is a c++ class (bunch of code) that user don't know its 
    implementation detail. It could be treated as general processing unit. 
  - Effect class accepts 2 kinds of inputs: 1) buffer, 2) const
    - Buffer stores vertex and pixel data.
    - Buffer can hold both GPU and CPU data.
    - Pixel buffer can havel sub buffers:
      - Each mipmap of a top-level texture can be a independant sub texture
        - sub textures can't have mipmaps.
      - Each face of a cube texture can have a 2D texture.
      - Each slice of a 3D texture can be a 2D texture.
    - Consts are pure CPU data.

RESOLVED ISSUES
===============
- Is effect ID compiled-time constant?
  - Yes
  - pros:
    - less error prone: can do compile time check.
  - cons: runtime creation of new effect is impossible.

- Is it desirable to create multiple instances of single effect?
  - No.
    Why we need that?

- Is it beneficial to group different types of constants into single buffer?
  - No.
    Independant constants are easy and intuitive to use.

- Is it possible to use meta data to describe interface of a effect class? Then 
  use an script to generate the c++ class interface.
  - No.
    All effects will have same interface. Effect parameters are referenced 
    by name and/or handle.
    Could be implemented using wrapper class in the future.

- Is it possible to extend an exising effect library without knowing its 
  internal implementation details?
  - No.
    If a effect library is mean to be extensible, it should provide its own
    interfaces and rules for effect and surface implementation.

OPEN ISSUES
===========

- Is it possible to implement effect with CUDA?

RESOLVED USER SCENARIOS
=======================

- create MSAA surface, render to it, then use it as texture.
  - create surface with hint: "msaa=true"
  - inside surface class, it'll hold a MSAA render target and a non-MSAA 
    texture, and copy/downsample data from RT to texture as needed.

- one shader output a 2D texture that is used as input of another shader that 
  requires 3D texture.

- one shader output a 2D texture that is used by many-many of other shaders.

- 2 draws use same shader. the 1st draw render to texture; the second draw 
  to back buffer.

- render to one face of a cubemap, or one slice of a 3D texture, or one mipmap 
  level of a 2D texture

- adjust effect behavior from outside
  - use effect parameter.

- separate depth and stencil buffer.
  - why?

- Adjust global quality parameter (like texture filtering), to increase overall
  rendering quality.
  - bad design. effects should control quality by themselves.

OPENED USER SCENARIOS
=====================

- user creates too many render targets that can't fit into hardware's local
  memory (like EDRAM)
  - may be resolved by lazy creation
  - check CPU "register renaming" and "buffer renaming" in graphics driver for
    more ideas.
  - by now, we leave that to application: application should always check
    return value of surface creation method.

- effect convert general CPU data buffer to whatever format it needs:
  - create specific vertice buffer from fat vertex buffer
  - create DXT texture from bitmap image
  - create cubemap from 6 2D textures
  - create mipmpas from single image
  - create normal map from height map
